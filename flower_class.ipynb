{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"flower_class.ipynb","provenance":[{"file_id":"1AS1K-AiJV7p6gKC5fuzCAOBZa86fcw7y","timestamp":1586032432940},{"file_id":"https://github.com/AnnaFilipov93/flowers-analyzer/blob/master/flower_proj_5_flowers.ipynb","timestamp":1585773701888}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DiTqxi6xeHeG","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"T958JYInd1l6","colab_type":"code","colab":{}},"source":["import cv2\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Activation, Dropout,Flatten,Conv2D,MaxPool2D,Dense\n","from tensorflow.keras.preprocessing import image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6MX2J75eaOK","colab_type":"code","outputId":"43229890-04f3-47bb-d527-ca66af0a1db9","executionInfo":{"status":"ok","timestamp":1586096737306,"user_tz":-180,"elapsed":17449,"user":{"displayName":"Vadim Dol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgT9Ymxy5iLiseBJGr4KHgOATcfWeiCbyNqIdYXSg=s64","userId":"03353320284049124983"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["! git clone https://github.com/AnnaFilipov93/flowers-analyzer"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cloning into 'flowers-analyzer'...\n","remote: Enumerating objects: 35, done.\u001b[K\n","remote: Counting objects: 100% (35/35), done.\u001b[K\n","remote: Compressing objects: 100% (30/30), done.\u001b[K\n","remote: Total 4404 (delta 8), reused 30 (delta 5), pack-reused 4369\u001b[K\n","Receiving objects: 100% (4404/4404), 368.70 MiB | 45.58 MiB/s, done.\n","Resolving deltas: 100% (12/12), done.\n","Checking out files: 100% (8710/8710), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OhH7EPmId1mA","colab_type":"code","colab":{}},"source":["#prepering the data\n","image_gen=ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n","                             height_shift_range=0.1, rescale=1/255,\n","                            shear_range=0.2, zoom_range=0.2,\n","                            horizontal_flip=True, fill_mode='nearest')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vR3-tdmd1mE","colab_type":"code","outputId":"2a112928-e75d-408a-e599-b55a37592cdd","executionInfo":{"status":"ok","timestamp":1586096655659,"user_tz":-180,"elapsed":7825,"user":{"displayName":"Vadim Dol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgT9Ymxy5iLiseBJGr4KHgOATcfWeiCbyNqIdYXSg=s64","userId":"03353320284049124983"}},"colab":{"base_uri":"https://localhost:8080/","height":697}},"source":["###~~~building the model~~~###\n","\n","model=Sequential()\n","\n","#conv layer I\n","model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(240,240,3),\n","                 activation='relu'))\n","#pooling layer I\n","model.add(MaxPool2D(pool_size=(2,2)))\n","\n","#conv layer II\n","model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=(240,240,3),\n","                 activation='relu'))\n","#pooling layer II\n","model.add(MaxPool2D(pool_size=(2,2)))\n","\n","#conv layer III\n","model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=(240,240,3),\n","                 activation='relu'))\n","#pooling layer III\n","model.add(MaxPool2D(pool_size=(2,2)))\n","\n","#conv layer IV\n","model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=(240,240,3),\n","                 activation='relu'))\n","#pooling layer IV\n","model.add(MaxPool2D(pool_size=(2,2)))\n","\n","#conv layer V\n","model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=(240,240,3),\n","                 activation='relu'))\n","#pooling layer V\n","model.add(MaxPool2D(pool_size=(2,2)))\n","\n","#conv layer VI\n","model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=(240,240,3),\n","                 activation='relu'))\n","#pooling layer VI\n","model.add(MaxPool2D(pool_size=(2,2)))\n","\n","#flatten\n","model.add(Flatten())\n","\n","#Dense layer\n","model.add(Dense(128,activation='relu'))\n","\n","#dropout layer\n","model.add(Dropout(0.5))\n","\n","#output layer\n","model.add(Dense(5,activation='sigmoid'))\n","\n","model.summary()\n","\n","#compile\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 238, 238, 32)      896       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 119, 119, 32)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 117, 117, 64)      18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 58, 58, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 56, 56, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 26, 26, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 1, 1, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 64)                0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               8320      \n","_________________________________________________________________\n","dropout (Dropout)            (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 5)                 645       \n","=================================================================\n","Total params: 176,069\n","Trainable params: 176,069\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HmNdgLTrd1mI","colab_type":"code","outputId":"15a8199f-21a3-4d68-a537-ce233a7c83f9","executionInfo":{"status":"ok","timestamp":1586097254084,"user_tz":-180,"elapsed":1199,"user":{"displayName":"Vadim Dol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgT9Ymxy5iLiseBJGr4KHgOATcfWeiCbyNqIdYXSg=s64","userId":"03353320284049124983"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["##~~reading the data ~~##\n","train_dir=os.path.join(os.getcwd(), 'flowers-analyzer/flowers/FLOWERS/train')\n","test_dir=os.path.join(os.getcwd(), 'flowers-analyzer/flowers/FLOWERS/test')\n","\n","train_img=image_gen.flow_from_directory(train_dir,\n","                                         target_size=(240,240), batch_size=32,\n","                                       class_mode='categorical')\n","\n","\n","test_img=image_gen.flow_from_directory(test_dir,\n","                                       target_size=(240,240), batch_size=16, \n","                                        class_mode='categorical')\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Found 7002 images belonging to 5 classes.\n","Found 850 images belonging to 5 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7YVQWried1mO","colab_type":"code","outputId":"12487ac3-17cc-4240-fc5c-c34ad2d0eb49","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["###~~~training the model~~~###\n","\n","results=model.fit_generator(train_img,epochs=150, steps_per_epoch=219,\n","                            validation_data=test_img, validation_steps=54)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","219/219 [==============================] - 112s 510ms/step - loss: 0.7703 - accuracy: 0.7121 - val_loss: 0.8268 - val_accuracy: 0.6882\n","Epoch 2/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.7208 - accuracy: 0.7331 - val_loss: 0.8598 - val_accuracy: 0.6812\n","Epoch 3/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.6911 - accuracy: 0.7379 - val_loss: 0.7929 - val_accuracy: 0.7000\n","Epoch 4/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.6833 - accuracy: 0.7441 - val_loss: 0.7967 - val_accuracy: 0.7224\n","Epoch 5/150\n","219/219 [==============================] - 113s 514ms/step - loss: 0.6558 - accuracy: 0.7531 - val_loss: 0.9407 - val_accuracy: 0.6659\n","Epoch 6/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.6441 - accuracy: 0.7552 - val_loss: 0.7871 - val_accuracy: 0.7000\n","Epoch 7/150\n","219/219 [==============================] - 113s 514ms/step - loss: 0.6229 - accuracy: 0.7658 - val_loss: 0.7843 - val_accuracy: 0.7224\n","Epoch 8/150\n","219/219 [==============================] - 112s 511ms/step - loss: 0.5980 - accuracy: 0.7744 - val_loss: 0.7219 - val_accuracy: 0.7388\n","Epoch 9/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.5865 - accuracy: 0.7773 - val_loss: 0.7199 - val_accuracy: 0.7329\n","Epoch 10/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.5737 - accuracy: 0.7831 - val_loss: 0.8638 - val_accuracy: 0.6659\n","Epoch 11/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.5705 - accuracy: 0.7809 - val_loss: 0.8999 - val_accuracy: 0.6835\n","Epoch 12/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.5528 - accuracy: 0.7918 - val_loss: 1.0567 - val_accuracy: 0.6318\n","Epoch 13/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.5365 - accuracy: 0.7942 - val_loss: 0.7468 - val_accuracy: 0.7271\n","Epoch 14/150\n","219/219 [==============================] - 112s 510ms/step - loss: 0.5234 - accuracy: 0.7968 - val_loss: 0.7852 - val_accuracy: 0.7282\n","Epoch 15/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.5225 - accuracy: 0.8006 - val_loss: 1.1062 - val_accuracy: 0.6294\n","Epoch 16/150\n","219/219 [==============================] - 113s 514ms/step - loss: 0.5190 - accuracy: 0.8029 - val_loss: 0.7505 - val_accuracy: 0.7553\n","Epoch 17/150\n","219/219 [==============================] - 112s 511ms/step - loss: 0.5027 - accuracy: 0.8058 - val_loss: 0.7749 - val_accuracy: 0.7506\n","Epoch 18/150\n","219/219 [==============================] - 113s 514ms/step - loss: 0.4832 - accuracy: 0.8156 - val_loss: 0.7619 - val_accuracy: 0.7153\n","Epoch 19/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.4925 - accuracy: 0.8142 - val_loss: 0.7730 - val_accuracy: 0.7247\n","Epoch 20/150\n","219/219 [==============================] - 112s 514ms/step - loss: 0.4809 - accuracy: 0.8189 - val_loss: 0.7275 - val_accuracy: 0.7553\n","Epoch 21/150\n","219/219 [==============================] - 113s 514ms/step - loss: 0.4696 - accuracy: 0.8232 - val_loss: 0.9165 - val_accuracy: 0.7129\n","Epoch 22/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.4552 - accuracy: 0.8268 - val_loss: 0.8684 - val_accuracy: 0.7118\n","Epoch 23/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.4593 - accuracy: 0.8235 - val_loss: 0.9554 - val_accuracy: 0.6741\n","Epoch 24/150\n","219/219 [==============================] - 113s 514ms/step - loss: 0.4418 - accuracy: 0.8346 - val_loss: 0.7748 - val_accuracy: 0.7176\n","Epoch 25/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.4150 - accuracy: 0.8426 - val_loss: 0.9547 - val_accuracy: 0.6941\n","Epoch 26/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.4463 - accuracy: 0.8345 - val_loss: 0.9544 - val_accuracy: 0.6906\n","Epoch 27/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.4240 - accuracy: 0.8375 - val_loss: 0.9776 - val_accuracy: 0.6906\n","Epoch 28/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.4097 - accuracy: 0.8438 - val_loss: 0.9322 - val_accuracy: 0.6918\n","Epoch 29/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.4048 - accuracy: 0.8485 - val_loss: 1.0433 - val_accuracy: 0.7259\n","Epoch 30/150\n","219/219 [==============================] - 113s 515ms/step - loss: 0.4176 - accuracy: 0.8420 - val_loss: 0.8647 - val_accuracy: 0.7282\n","Epoch 31/150\n","219/219 [==============================] - 112s 512ms/step - loss: 0.3923 - accuracy: 0.8559 - val_loss: 0.9111 - val_accuracy: 0.7047\n","Epoch 32/150\n","219/219 [==============================] - 112s 511ms/step - loss: 0.3905 - accuracy: 0.8552 - val_loss: 0.9006 - val_accuracy: 0.7094\n","Epoch 33/150\n","219/219 [==============================] - 112s 514ms/step - loss: 0.3765 - accuracy: 0.8606 - val_loss: 0.8714 - val_accuracy: 0.6918\n","Epoch 34/150\n","219/219 [==============================] - 113s 515ms/step - loss: 0.3828 - accuracy: 0.8579 - val_loss: 0.7584 - val_accuracy: 0.7600\n","Epoch 35/150\n","219/219 [==============================] - 113s 516ms/step - loss: 0.3697 - accuracy: 0.8640 - val_loss: 0.9612 - val_accuracy: 0.7106\n","Epoch 36/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.3661 - accuracy: 0.8612 - val_loss: 1.1968 - val_accuracy: 0.6588\n","Epoch 37/150\n","219/219 [==============================] - 112s 513ms/step - loss: 0.3652 - accuracy: 0.8602 - val_loss: 0.8598 - val_accuracy: 0.7494\n","Epoch 38/150\n","219/219 [==============================] - 113s 515ms/step - loss: 0.3513 - accuracy: 0.8698 - val_loss: 1.0919 - val_accuracy: 0.6859\n","Epoch 39/150\n","219/219 [==============================] - 113s 515ms/step - loss: 0.3597 - accuracy: 0.8629 - val_loss: 0.8322 - val_accuracy: 0.7671\n","Epoch 40/150\n","219/219 [==============================] - 113s 515ms/step - loss: 0.3513 - accuracy: 0.8688 - val_loss: 0.9794 - val_accuracy: 0.7118\n","Epoch 41/150\n","219/219 [==============================] - 113s 516ms/step - loss: 0.3244 - accuracy: 0.8780 - val_loss: 1.0609 - val_accuracy: 0.7024\n","Epoch 42/150\n","219/219 [==============================] - 113s 514ms/step - loss: 0.3358 - accuracy: 0.8713 - val_loss: 0.8839 - val_accuracy: 0.7588\n","Epoch 43/150\n","217/219 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.8796"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aVJEfSAZd1mS","colab_type":"code","colab":{}},"source":["model.save('five_flowers_model.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yT5YHyrBd1mW","colab_type":"code","colab":{}},"source":["def pred (p, pred_acc):\n","    if pred_acc[0,p]<0.7:\n","        print(\"the model couldn't recognize it\")\n","    elif p==0:\n","        print(\"the model recognized it as a daisy\")\n","    elif p==1:\n","         print(\"the model recognized it as a dandelion\")\n","    elif p==2:\n","          print(\"the model recognized it as a rose\")\n","    elif p==3:\n","          print(\"the model recognized it as a sunflower\")       \n","    elif p==4:\n","          print(\"the model recognized it as a tulip\")     \n","            "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UBs7UMsId1mb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlHxfhe-d1me","colab_type":"code","colab":{}},"source":["###~~~testing on the tests images~~~###\n","\n","examples = ['FLOWERS//test//daisy/144076848_57e1d662e3_m.jpg',\n","            'FLOWERS//test//dandelion/14740350060_a489d9fa06.jpg',\n","            'FLOWERS//test/tulip/5633266048_4f4bfb2cf1_n.jpg',\n","            'FLOWERS//test/sunflower/21728822928_9f6817325a_n.jpg',\n","            'flowers//FLOWERS//test//rose/random_flower.jpg']\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXd-itTpd1mh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uCaATLjEgxK","colab_type":"code","colab":{}},"source":["def predict_flower(path):\n","  flower=cv2.imread(path)\n","  flower=cv2.cvtColor(flower,cv2.COLOR_BGR2RGB)\n","  plt.imshow(flower)\n","\n","  flower_file=path\n","  flower_img=image.load_img(flower_file, target_size=(240,240))\n","  flower_img=image.img_to_array(flower_img)\n","  flower_img=np.expand_dims(flower_img,axis=0)\n","  flower_img=flower_img/255\n","\n","  p=model.predict_classes(flower_img)\n","  pred(p)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n036mjCud1my","colab_type":"code","colab":{}},"source":["model=load_model('five_flowers_model.h5')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JgTHDgKOzIb9","colab_type":"text"},"source":["---### This is a single use script used to manipulate existing data and created randomly altered new images by the means of rotation, adding noise, smoothening the image and creating mirror images. ###---"]},{"cell_type":"code","metadata":{"id":"PyLeI078d1m3","colab_type":"code","outputId":"246ff52f-e223-4752-90c2-eae20f013bc1","executionInfo":{"status":"ok","timestamp":1586096795318,"user_tz":-180,"elapsed":54373,"user":{"displayName":"Vadim Dol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgT9Ymxy5iLiseBJGr4KHgOATcfWeiCbyNqIdYXSg=s64","userId":"03353320284049124983"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import glob\n","import os\n","import cv2\n","import random\n","from PIL import Image\n","from skimage.util import random_noise\n","from zipfile import ZipFile\n","\n","# extra script to augment data (!!! One time use !!!)\n","\n","PATH_TO_IMAGES = 'flowers-analyzer/flowers/FLOWERS/train/'\n","PREFIX = '/augmented_'\n","  \n","sub_directories = os.listdir(PATH_TO_IMAGES)\n","\n","for sub_dir in sub_directories:\n","  sub_dir_path = PATH_TO_IMAGES + sub_dir\n","  images = [cv2.imread(file) for file in glob.glob(sub_dir_path + '/*.jpg')]\n","  aug_images = []\n","\n","  for im in images:\n","\n","    rand = random.randint(1, 5)\n","    augmented_image = None\n","\n","    if rand == 1:\n","      angle= random.randint(0,90)\n","      im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","      im_pil = Image.fromarray(im)\n","      rotated = im_pil.rotate(-angle)\n","      augmented_image = np.asarray(rotated)\n","        \n","    elif rand == 2:\n","      angle= random.randint(0,90)\n","      im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","      im_pil = Image.fromarray(im)\n","      rotated = im_pil.rotate(angle)\n","      augmented_image = np.asarray(rotated)\n","\n","    elif rand == 3:\n","      augmented_image = np.fliplr(im)\n","\n","    elif rand == 4:\n","      noise_img = random_noise(im, mode='s&p',amount=0.005)\n","      augmented_image = np.array(255*noise_img, dtype = 'uint8')\n","\n","    else:\n","      augmented_image = cv2.GaussianBlur(im, (9,9), cv2.BORDER_DEFAULT)\n","\n","    aug_images.append(augmented_image)\n","\n","  counter = 0\n","  for image in aug_images:\n","    img_name = sub_dir_path + PREFIX + str(counter) + '.jpg'\n","    cv2.imwrite(img_name, image)\n","    counter = counter + 1\n","\n","'''with ZipFile('flowers.zip', 'w') as zipObj:\n","\n","   for folderName, subfolders, filenames in os.walk(PATH_TO_IMAGES):\n","\n","       for filename in filenames:\n","           #create complete filepath of file in directory\n","           filePath = os.path.join(folderName, filename)\n","           # Add file to zip\n","           zipObj.write(filePath)\n","'''\n","print('Augmented images created...')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Augmented images created...\n"],"name":"stdout"}]}]}