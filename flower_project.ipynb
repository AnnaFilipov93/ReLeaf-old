{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout,Flatten,Conv2D,MaxPool2D,Dense\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1c877c3336dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#preparing the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m image_gen=ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \n\u001b[0m\u001b[0;32m      3\u001b[0m                             \u001b[0mheight_shift_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshear_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "#preparing the data\n",
    "image_gen=ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \n",
    "                            height_shift_range=0.1, rescale=1/255, shear_range=0.2,\n",
    "                            zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "image_shape=(240,240,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0bae7aaf616e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#convolutional layer_I\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "##~~building the model~~##\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "#convolutional layer_I\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=image_shape,activation='relu'))\n",
    "#pool layer_I\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#convolutional layer_II\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),input_shape=image_shape,activation='relu'))\n",
    "#pool layer_II\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#convolutional layer_III\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),input_shape=image_shape,activation='relu'))\n",
    "#pool layer_III\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#dense layer\n",
    "model.add(Dense(128,activation='relu'))\n",
    "\n",
    "#dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "#compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1401 images belonging to 2 classes.\n",
      "Found 143 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "##~~reading the data~~##\n",
    "\n",
    "train_img=image_gen.flow_from_directory('FLOWERS\\\\train',\n",
    "                                         target_size=image_shape[:2], batch_size=16, class_mode='binary')\n",
    "\n",
    "test_img=image_gen.flow_from_directory('FLOWERS\\\\test',\n",
    "                                         target_size=image_shape[:2], batch_size=16, class_mode='binary')\n",
    "\n",
    "#train_img.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 71s 946ms/step - loss: 0.4646 - acc: 0.7881 - val_loss: 0.2876 - val_acc: 0.8531\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 69s 915ms/step - loss: 0.3150 - acc: 0.8817 - val_loss: 0.4307 - val_acc: 0.8252\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 61s 813ms/step - loss: 0.3112 - acc: 0.8908 - val_loss: 0.3027 - val_acc: 0.8671\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 58s 772ms/step - loss: 0.2610 - acc: 0.9108 - val_loss: 0.3578 - val_acc: 0.8322\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 62s 832ms/step - loss: 0.2488 - acc: 0.9037 - val_loss: 0.3989 - val_acc: 0.8182\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 62s 822ms/step - loss: 0.2731 - acc: 0.9158 - val_loss: 0.3165 - val_acc: 0.8182\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 62s 829ms/step - loss: 0.2126 - acc: 0.9250 - val_loss: 0.2718 - val_acc: 0.8811\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 57s 766ms/step - loss: 0.1891 - acc: 0.9283 - val_loss: 0.3468 - val_acc: 0.8322\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 69s 917ms/step - loss: 0.1997 - acc: 0.9267 - val_loss: 0.2994 - val_acc: 0.8601\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 67s 895ms/step - loss: 0.1723 - acc: 0.9394 - val_loss: 0.3680 - val_acc: 0.8671\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 69s 919ms/step - loss: 0.1719 - acc: 0.9317 - val_loss: 0.2519 - val_acc: 0.8951\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 66s 876ms/step - loss: 0.1673 - acc: 0.9358 - val_loss: 0.2967 - val_acc: 0.8531\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 61s 819ms/step - loss: 0.1668 - acc: 0.9400 - val_loss: 0.2524 - val_acc: 0.8881\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 66s 887ms/step - loss: 0.1933 - acc: 0.9329 - val_loss: 0.3839 - val_acc: 0.8462\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 51s 677ms/step - loss: 0.1760 - acc: 0.9358 - val_loss: 0.3135 - val_acc: 0.8601\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 65s 860ms/step - loss: 0.1336 - acc: 0.9483 - val_loss: 0.2338 - val_acc: 0.8881\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 63s 846ms/step - loss: 0.1665 - acc: 0.9383 - val_loss: 0.4625 - val_acc: 0.8042\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 60s 797ms/step - loss: 0.1345 - acc: 0.9425 - val_loss: 0.2945 - val_acc: 0.8741\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 58s 777ms/step - loss: 0.1615 - acc: 0.9394 - val_loss: 0.2674 - val_acc: 0.8881\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 55s 731ms/step - loss: 0.2030 - acc: 0.9297 - val_loss: 0.2409 - val_acc: 0.9161\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 68s 911ms/step - loss: 0.1482 - acc: 0.9435 - val_loss: 0.3583 - val_acc: 0.8322\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 57s 758ms/step - loss: 0.1358 - acc: 0.9429 - val_loss: 0.3430 - val_acc: 0.8392\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 69s 916ms/step - loss: 0.1139 - acc: 0.9617 - val_loss: 0.2214 - val_acc: 0.9161\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 63s 846ms/step - loss: 0.1090 - acc: 0.9517 - val_loss: 0.2857 - val_acc: 0.9161\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 67s 889ms/step - loss: 0.1893 - acc: 0.9427 - val_loss: 0.2794 - val_acc: 0.8881\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 68s 907ms/step - loss: 0.1232 - acc: 0.9544 - val_loss: 0.3812 - val_acc: 0.8322\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 65s 867ms/step - loss: 0.1126 - acc: 0.9575 - val_loss: 0.2764 - val_acc: 0.8881\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 72s 963ms/step - loss: 0.1073 - acc: 0.9517 - val_loss: 0.2927 - val_acc: 0.8881\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 67s 887ms/step - loss: 0.1053 - acc: 0.9529 - val_loss: 0.3016 - val_acc: 0.8951\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 56s 750ms/step - loss: 0.1268 - acc: 0.9485 - val_loss: 0.2897 - val_acc: 0.8881\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 61s 815ms/step - loss: 0.1314 - acc: 0.9450 - val_loss: 0.2742 - val_acc: 0.9021\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 64s 847ms/step - loss: 0.1020 - acc: 0.9581 - val_loss: 0.3274 - val_acc: 0.8741\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 63s 835ms/step - loss: 0.0974 - acc: 0.9567 - val_loss: 0.3427 - val_acc: 0.8531\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 57s 766ms/step - loss: 0.0934 - acc: 0.9650 - val_loss: 0.4679 - val_acc: 0.8811\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 70s 934ms/step - loss: 0.1132 - acc: 0.9519 - val_loss: 0.2850 - val_acc: 0.8811\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 65s 863ms/step - loss: 0.1108 - acc: 0.9525 - val_loss: 0.2567 - val_acc: 0.8811\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 54s 723ms/step - loss: 0.0847 - acc: 0.9635 - val_loss: 0.3298 - val_acc: 0.8741\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 59s 781ms/step - loss: 0.0974 - acc: 0.9592 - val_loss: 0.4305 - val_acc: 0.9021\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 64s 855ms/step - loss: 0.0960 - acc: 0.9642 - val_loss: 0.3413 - val_acc: 0.9091\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 62s 833ms/step - loss: 0.0877 - acc: 0.9635 - val_loss: 0.4721 - val_acc: 0.8601\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 51s 679ms/step - loss: 0.0818 - acc: 0.9692 - val_loss: 0.4136 - val_acc: 0.9021\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 55s 737ms/step - loss: 0.1015 - acc: 0.9542 - val_loss: 0.4141 - val_acc: 0.8741\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 63s 834ms/step - loss: 0.1126 - acc: 0.9483 - val_loss: 0.3687 - val_acc: 0.8601\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 65s 861ms/step - loss: 0.0713 - acc: 0.9717 - val_loss: 0.3166 - val_acc: 0.9091\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 58s 773ms/step - loss: 0.0784 - acc: 0.9658 - val_loss: 0.3388 - val_acc: 0.8951\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 57s 754ms/step - loss: 0.0808 - acc: 0.9667 - val_loss: 0.2852 - val_acc: 0.9231\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 64s 854ms/step - loss: 0.0792 - acc: 0.9700 - val_loss: 0.4372 - val_acc: 0.9161\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 66s 878ms/step - loss: 0.0803 - acc: 0.9687 - val_loss: 0.3780 - val_acc: 0.9091\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 64s 859ms/step - loss: 0.0750 - acc: 0.9683 - val_loss: 0.5394 - val_acc: 0.8811\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 53s 709ms/step - loss: 0.0669 - acc: 0.9775 - val_loss: 0.4801 - val_acc: 0.9161\n"
     ]
    }
   ],
   "source": [
    "##~~fitting the model~~##\n",
    "\n",
    "results=model.fit_generator(train_img, epochs=50,steps_per_epoch=75, validation_data=test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-800878e4f077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C://Users//Orit//Desktop//Computer-Vision-with-Python//FLOWERS//test//sunflower/22416421196_caf131c9fa_m.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mflower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflower\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mflower_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "path='C://Users//Orit//Desktop//Computer-Vision-with-Python//FLOWERS//test//sunflower/22416421196_caf131c9fa_m.jpg'\n",
    "flower=cv2.cvtColor(flower,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(flower)\n",
    "\n",
    "flower_file=path\n",
    "flower_img=image.load_img(flower_file, target_size=(240,240))\n",
    "flower_img=image.img_to_array(flower_img)\n",
    "flower_img=np.expand_dims(flower_img,axis=0)\n",
    "flower_img=flower_img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model recognized it as a sunflower\n"
     ]
    }
   ],
   "source": [
    "p=model.predict_classes(flower_img)\n",
    "\n",
    "pred(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred (p):\n",
    "    if p==0:\n",
    "        print(\"the model recognized it as a rose\")\n",
    "    elif p==1:\n",
    "         print(\"the model recognized it as a sunflower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rose_sunflower_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
